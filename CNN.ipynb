{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CNN for AdvSND target energy reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import reshape_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use([\"science\", \"notebook\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = 14\n",
    "plt.rcParams[\"axes.formatter.limits\"] = -5, 4\n",
    "plt.rcParams[\"figure.figsize\"] = 6, 4\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = \"dataframe_CC_saturation5_train.root:df\"\n",
    "filename_test = \"dataframe_CC_saturation5_test.root:df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_train = uproot.open(filename_train)\n",
    "events_test = uproot.open(filename_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = events_train.num_entries + events_test.num_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"lepton_energy\"\n",
    "\n",
    "target_pretty = \"Lepton Energy\"\n",
    "target_LaTeX = \"E_\\ell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"hadron_energy\"\n",
    "\n",
    "target_pretty = \"Hadron Energy\"\n",
    "target_LaTeX = \"E_h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"nu_energy\"\n",
    "\n",
    "target_pretty = \"Neutrino energy\"\n",
    "target_LaTeX = \"E_\\nu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"start_z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"both\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"deps\"\n",
    "edep_correction = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_generator(train=True):\n",
    "    events = events_train if train else events_test\n",
    "    log = \"energy\" in target\n",
    "    for batch, report in events.iterate(step_size=1, report=True, library=\"np\"):\n",
    "        for i in range(batch[\"X\"].shape[0]):\n",
    "            yield (\n",
    "                batch[\"X\"].astype(np.float16)[i],\n",
    "                batch[\"X_mufilter\"].astype(np.float16)[i],\n",
    "                (np.log(batch[target][i]) if log else batch[target][i]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = event_generator(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100, 3072, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = gen.__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(sample[0], aspect=0.05)\n",
    "plt.figure()\n",
    "plt.imshow(sample[1], aspect=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_spec_0 = tf.type_spec_from_value(gen.__next__()[0])\n",
    "generator_spec_1 = tf.type_spec_from_value(gen.__next__()[1])\n",
    "generator_spec_2 = tf.type_spec_from_value(gen.__next__()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO reshape data only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        event_generator,\n",
    "        output_signature=(\n",
    "            generator_spec_0,\n",
    "            generator_spec_1,\n",
    "            generator_spec_2,\n",
    "        ),\n",
    "    )\n",
    "    .map(reshape_data)\n",
    "    .apply(tf.data.experimental.assert_cardinality(events_train.num_entries))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        event_generator,\n",
    "        args=[False],\n",
    "        output_signature=(\n",
    "            generator_spec_0,\n",
    "            generator_spec_1,\n",
    "            generator_spec_2,\n",
    "        ),\n",
    "    )\n",
    "    .map(reshape_data)\n",
    "    .apply(tf.data.experimental.assert_cardinality(events_test.num_entries))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = events_test[\"energy_dep_target\"].array() + edep_correction, events_test[\"energy_dep_mufilter\"].array()+edep_correction\n",
    "y_test = (\n",
    "    np.log(events_test[target].array())\n",
    "    if \"energy\" in target\n",
    "    else events_test[target].array()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ds_train = ds_train.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_ds_test = ds_test.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Concatenate\n",
    "import tensorflow.keras.optimizers\n",
    "import tensorflow.keras.metrics\n",
    "import tensorflow.keras.losses\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "K.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"CNN_3dSat5_grandjorasses_{target}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_middle = 0.25\n",
    "\n",
    "lr = 2e-4  # ; betaa1=30; betaa2=100; decay=1e-3\n",
    "\n",
    "# AdvTarget\n",
    "\n",
    "# TODO bigger kernels/windows in strip dimension (axis=1)?\n",
    "\n",
    "target_h_input = Input(input_shape, name=\"target_h_in\")\n",
    "X_h = Conv2D(16, kernel_size=(1, 9), padding=\"same\")(target_h_input)\n",
    "X_h = BatchNormalization()(X_h)\n",
    "X_h = ReLU()(X_h)\n",
    "X_h = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_h)\n",
    "X_h = Dropout(rate=drop_middle)(X_h)\n",
    "\n",
    "X_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_h)\n",
    "X_h = BatchNormalization()(X_h)\n",
    "X_h = ReLU()(X_h)\n",
    "X_h = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_h)\n",
    "X_h = Dropout(rate=drop_middle)(X_h)\n",
    "\n",
    "X_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_h)\n",
    "X_h = BatchNormalization()(X_h)\n",
    "X_h = ReLU()(X_h)\n",
    "X_h = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_h)\n",
    "X_h = Dropout(rate=drop_middle)(X_h)\n",
    "\n",
    "X_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_h)\n",
    "X_h = BatchNormalization()(X_h)\n",
    "X_h = ReLU()(X_h)\n",
    "X_h = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(X_h)\n",
    "\n",
    "X_h = Flatten()(X_h)\n",
    "\n",
    "target_v_input = Input(input_shape, name=\"target_v_in\")\n",
    "X_v = Conv2D(16, kernel_size=(1, 9), padding=\"same\")(target_v_input)\n",
    "X_v = BatchNormalization()(X_v)\n",
    "X_v = ReLU()(X_v)\n",
    "X_v = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_v)\n",
    "X_v = Dropout(rate=drop_middle)(X_v)\n",
    "\n",
    "X_v = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_v)\n",
    "X_v = BatchNormalization()(X_v)\n",
    "X_v = ReLU()(X_v)\n",
    "X_v = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_v)\n",
    "X_v = Dropout(rate=drop_middle)(X_v)\n",
    "\n",
    "X_v = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_v)\n",
    "X_v = BatchNormalization()(X_v)\n",
    "X_v = ReLU()(X_v)\n",
    "X_v = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_v)\n",
    "X_v = Dropout(rate=drop_middle)(X_v)\n",
    "\n",
    "X_v = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_v)\n",
    "X_v = BatchNormalization()(X_v)\n",
    "X_v = ReLU()(X_v)\n",
    "X_v = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(X_v)\n",
    "\n",
    "X_v = Flatten()(X_v)\n",
    "\n",
    "# AdvTarget\n",
    "\n",
    "mufilter_h_input = Input((21, 4608, 1), name=\"mufilter_h_in\")\n",
    "X_mf_h = Conv2D(16, kernel_size=(1, 3), padding=\"same\")(mufilter_h_input)\n",
    "X_mf_h = BatchNormalization()(X_mf_h)\n",
    "X_mf_h = ReLU()(X_mf_h)\n",
    "X_mf_h = MaxPooling2D(pool_size=(1, 4), padding=\"valid\")(X_mf_h)\n",
    "X_mf_h = Dropout(rate=drop_middle)(X_mf_h)\n",
    "\n",
    "X_mf_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_mf_h)\n",
    "X_mf_h = BatchNormalization()(X_mf_h)\n",
    "X_mf_h = ReLU()(X_mf_h)\n",
    "X_mf_h = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_mf_h)\n",
    "X_mf_h = Dropout(rate=drop_middle)(X_mf_h)\n",
    "\n",
    "X_mf_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_mf_h)\n",
    "X_mf_h = BatchNormalization()(X_mf_h)\n",
    "X_mf_h = ReLU()(X_mf_h)\n",
    "X_mf_h = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_mf_h)\n",
    "X_mf_h = Dropout(rate=drop_middle)(X_mf_h)\n",
    "\n",
    "X_mf_h = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_mf_h)\n",
    "X_mf_h = BatchNormalization()(X_mf_h)\n",
    "X_mf_h = ReLU()(X_mf_h)\n",
    "X_mf_h = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(X_mf_h)\n",
    "\n",
    "X_mf_h = Flatten()(X_mf_h)\n",
    "\n",
    "mufilter_v_input = Input((5, 4608, 1), name=\"mufilter_v_in\")\n",
    "X_mf_v = Conv2D(16, kernel_size=(1, 3), padding=\"same\")(mufilter_v_input)\n",
    "X_mf_v = BatchNormalization()(X_mf_v)\n",
    "X_mf_v = ReLU()(X_mf_v)\n",
    "X_mf_v = MaxPooling2D(pool_size=(1, 4), padding=\"valid\")(X_mf_v)\n",
    "X_mf_v = Dropout(rate=drop_middle)(X_mf_v)\n",
    "\n",
    "X_mf_v = Conv2D(16, kernel_size=(2, 3), padding=\"same\")(X_mf_v)\n",
    "X_mf_v = BatchNormalization()(X_mf_v)\n",
    "X_mf_v = ReLU()(X_mf_v)\n",
    "X_mf_v = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_mf_v)\n",
    "X_mf_v = Dropout(rate=drop_middle)(X_mf_v)\n",
    "\n",
    "X_mf_v = Conv2D(16, kernel_size=(2, 3), padding=\"same\")(X_mf_v)\n",
    "X_mf_v = BatchNormalization()(X_mf_v)\n",
    "X_mf_v = ReLU()(X_mf_v)\n",
    "X_mf_v = MaxPooling2D(pool_size=(2, 4), padding=\"valid\")(X_mf_v)\n",
    "X_mf_v = Dropout(rate=drop_middle)(X_mf_v)\n",
    "\n",
    "X_mf_v = Conv2D(16, kernel_size=(3, 3), padding=\"same\")(X_mf_v)\n",
    "X_mf_v = BatchNormalization()(X_mf_v)\n",
    "X_mf_v = ReLU()(X_mf_v)\n",
    "X_mf_v = MaxPooling2D(pool_size=(2, 2), padding=\"same\")(X_mf_v)\n",
    "\n",
    "X_mf_v = Flatten()(X_mf_v)\n",
    "\n",
    "X = Concatenate()([X_h, X_v, X_mf_h, X_mf_v])\n",
    "X = Dense(4)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = ReLU()(X)\n",
    "X = Dense(20)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = ReLU()(X)\n",
    "X = Dropout(rate=0.2)(X)\n",
    "# TODO Add dropout?\n",
    "# X_ell = Dense(1)(X)\n",
    "# X_had = Dense(1)(X)\n",
    "X = Dense(1)(X)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[target_h_input, target_v_input, mufilter_h_input, mufilter_v_input],\n",
    "    outputs=X,\n",
    "    name=model_name,\n",
    ")\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO activation for max pooling?\n",
    "# TODO Reduce number of convolutional layers?\n",
    "# TODO Add hidden hidden layer (or two?) before outputs?\n",
    "# TODO predict independently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_result = model.fit(\n",
    "    batched_ds_train.prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.concat([history_df, pd.DataFrame(fit_result.history)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.to_csv(f\"history_{model_name}_n{n_events}_e{len(history_df)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{model_name}_n{n_events}_e{len(history_df)}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "plt.title(\"CNN lepton + hadron energy\")\n",
    "ax1.plot(history_df[\"loss\"].values, color=colors[0])\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Loss Function\", color=colors[0])\n",
    "try:\n",
    "    ax2.plot(history_df[\"mae\"].values, color=colors[1])\n",
    "except KeyError:\n",
    "    ax2.plot(history_df[\"dense_2_mae\"].values, color=colors[1])\n",
    "    ax2.plot(history_df[\"dense_3_mae\"].values, color=colors[1])\n",
    "ax2.set_ylabel(\"Error\", color=colors[1])\n",
    "plt.text(\n",
    "    0.3,\n",
    "    0.7,\n",
    "    f\"Training dataset: {events_train.num_entries} events\\n\"\n",
    "    f\"Test dataset: {events_test.num_entries} events\\n\"\n",
    "    f\"Training duration: {len(history_df)} epochs\\n{model_name}\",\n",
    "    transform=ax1.transAxes,\n",
    ")\n",
    "plt.savefig(f\"plots/convergence_{model_name}_n{n_events}_e{len(history_df)}.pdf\")\n",
    "plt.savefig(f\"plots/convergence_{model_name}_n{n_events}_e{len(history_df)}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test=retoy_model.predict(x=[x_test['scifi_h'], x_test['scifi_v'], x_test['us'], x_test['ds']])\n",
    "y_pred = model.predict(batched_ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\"lepton_energy_pred\" : np.squeeze(np.exp(y_pred)[0]), \"lepton_energy_test\" : np.squeeze(np.exp(y_test)[0]),\n",
    "#                  \"hadron_energy_pred\" : np.squeeze(np.exp(y_pred)[1]), \"hadron_energy_test\" : np.squeeze(np.exp(y_test)[1])})\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        f\"{target}_pred\": np.squeeze(np.exp(y_pred)),\n",
    "        f\"{target}_test\": np.squeeze(np.exp(y_test)),\n",
    "    }\n",
    ")\n",
    "if \"energy\" not in target:\n",
    "    df = pd.DataFrame(\n",
    "        {f\"{target}_pred\": np.squeeze(y_pred), f\"{target}_test\": np.squeeze(y_test)}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{model_name}_n{n_events}_e{len(history_df)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{model_name}_n{n_events}_e{len(history_df)}.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
